{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convolutional Neurual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra, matrix multiplications\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_images=train_images.reshape(60000,28,28,1)\n",
    "test_images=test_images.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# convert train dataset to (num_images, img_rows, img_cols) format in order to plot it\n",
    "xtrain_vis = xtrain.values.reshape(ntrain, dim, dim)\n",
    "\n",
    "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html\n",
    "# subplot(2,3,3) = subplot(233)\n",
    "# a grid of 3x3 is created, then plots are inserted in some of these slots\n",
    "for i in range(0,9): # how many imgs will show from the 3x3 grid\n",
    "    plt.subplot(330 + (i+1)) # open next subplot\n",
    "    plt.imshow(xtrain_vis[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(ytrain[i]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heading ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_reshape(df):\n",
    "    print(\"Previous shape, pixels are in 1D vector:\", df.shape)\n",
    "    df = df.values.reshape(-1, dim, dim, 1) \n",
    "    # -1 means the dimension doesn't change, so 42000 in the case of xtrain and 28000 in the case of test\n",
    "    print(\"After reshape, pixels are a 28x28x1 3D matrix:\", df.shape)\n",
    "    return df\n",
    "\n",
    "xtrain = df_reshape(xtrain) # numpy.ndarray type\n",
    "test = df_reshape(test) # numpy.ndarray type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "print(type(ytrain))\n",
    "# number of classes, in this case 10\n",
    "nclasses = ytrain.max() - ytrain.min() + 1\n",
    "\n",
    "print(\"Shape of ytrain before: \", ytrain.shape) # (42000,)\n",
    "\n",
    "ytrain = to_categorical(ytrain, num_classes = nclasses)\n",
    "\n",
    "print(\"Shape of ytrain after: \", ytrain.shape) # (42000, 10), also numpy.ndarray type\n",
    "print(type(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 2\n",
    "np.random.seed(seed)\n",
    "\n",
    "# percentage of xtrain which will be xval\n",
    "split_pct = 0.1\n",
    "\n",
    "# Split the train and the validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(xtrain,\n",
    "                                              ytrain, \n",
    "                                              test_size=split_pct,\n",
    "                                              random_state=seed,\n",
    "                                              stratify=ytrain\n",
    "                                             )\n",
    "\n",
    "print(xtrain.shape, ytrain.shape, xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# for the architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPool2D, AvgPool2D\n",
    "\n",
    "# optimizer, data generator and learning rate reductor\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "dim = 28\n",
    "nclasses = 10\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(dim,dim,1)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu',))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(nclasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                 patience=3, \n",
    "                                 verbose=1, \n",
    "                                 factor=0.5, \n",
    "                                 min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "          featurewise_center=False,            # set input mean to 0 over the dataset\n",
    "          samplewise_center=False,             # set each sample mean to 0\n",
    "          featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "          samplewise_std_normalization=False,  # divide each input by its std\n",
    "          zca_whitening=False,                 # apply ZCA whitening\n",
    "          rotation_range=30,                   # randomly rotate images in the range (degrees, 0 to 180)\n",
    "          zoom_range = 0.1,                    # Randomly zoom image \n",
    "          width_shift_range=0.1,               # randomly shift images horizontally (fraction of total width)\n",
    "          height_shift_range=0.1,              # randomly shift images vertically (fraction of total height)\n",
    "          horizontal_flip=False,               # randomly flip images\n",
    "          vertical_flip=False)                 # randomly flip images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit_generator(datagen.flow(train_images,train_labels, batch_size=batch_size),\n",
    "                              epochs=epochs, \n",
    "                              validation_data=(test_images,test_labels),\n",
    "                              verbose=1, \n",
    "                              steps_per_epoch=train_images.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "ypred_onehot = model.predict(xval)\n",
    "# Convert predictions classes from one hot vectors to labels: [0 0 1 0 0 ...] --> 2\n",
    "ypred = np.argmax(ypred_onehot,axis=1)\n",
    "# Convert validation observations from one hot vectors to labels\n",
    "ytrue = np.argmax(yval,axis=1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(ytrue, ypred)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes=range(nclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (ypred - ytrue != 0) # array of bools with true when there is an error or false when the image is cor\n",
    "\n",
    "ypred_er = ypred_onehot[errors]\n",
    "ypred_classes_er = ypred[errors]\n",
    "ytrue_er = ytrue[errors]\n",
    "xval_er = xval[errors]\n",
    "\n",
    "def display_errors(errors_index, img_errors, pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows, ncols, sharex=True, sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "            \n",
    "# Probabilities of the wrong predicted numbers\n",
    "ypred_er_prob = np.max(ypred_er,axis=1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_er = np.diagonal(np.take(ypred_er, ytrue_er, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_er = ypred_er_prob - true_prob_er\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_delta_er = np.argsort(delta_pred_true_er)\n",
    "\n",
    "# Top 6 errors. You can change the range to see other images\n",
    "most_important_er = sorted_delta_er[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_er, xval_er, ypred_classes_er, ytrue_er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(test, verbose=1)\n",
    "\n",
    "submissions = pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                            \"Label\": predictions})\n",
    "\n",
    "submissions.to_csv(\"mnist2908.csv\", index=False, header=True)predictions = model.predict_classes(test, verbose=1)\n",
    "\n",
    "submissions = pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                            \"Label\": predictions})\n",
    "\n",
    "submissions.to_csv(\"mnist2908.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
